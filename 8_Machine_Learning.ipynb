{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Machine learning with scikit-learn"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### these lines to ignore some annoying - but harmless - depreciation warnings in pandas \n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext load_style"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_style ./styles/talk.css"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "\n",
        ".rendered_html {\n",
        "    font-family: \"proxima-nova\", helvetica;\n",
        "    font-size: 130%;\n",
        "    line-height: 1.5;\n",
        "}\n",
        "\n",
        ".rendered_html h1 {\n",
        "    margin: 0.25em 0em 0.5em;\n",
        "    color: #015C9C;\n",
        "    text-align: center;\n",
        "    line-height: 1.2; \n",
        "    page-break-before: always;\n",
        "}\n",
        "\n",
        ".rendered_html h2 {\n",
        "    margin: 1.1em 0em 0.5em;\n",
        "    color: #26465D;\n",
        "    line-height: 1.2;\n",
        "}\n",
        "\n",
        ".rendered_html h3 {\n",
        "    margin: 1.1em 0em 0.5em;\n",
        "    color: #002845;\n",
        "    line-height: 1.2;\n",
        "}\n",
        "\n",
        ".rendered_html li {\n",
        "    line-height: 1.5; \n",
        "}\n",
        "\n",
        "/*.prompt {\n",
        "    font-size: 120%; \n",
        "}*/\n",
        "\n",
        ".CodeMirror-lines {\n",
        "    font-size: 110%; \n",
        "}\n",
        "\n",
        "/*.output_area {\n",
        "    font-size: 120%; \n",
        "}*/\n",
        "\n",
        "/*#notebook {\n",
        "    background-image: url('files/images/witewall_3.png');\n",
        "}*/\n",
        "\n",
        "h1.bigtitle {\n",
        "    margin: 4cm 1cm 4cm 1cm;\n",
        "    font-size: 300%;\n",
        "}\n",
        "\n",
        "h3.point {\n",
        "    font-size: 200%;\n",
        "    text-align: center;\n",
        "    margin: 2em 0em 2em 0em;\n",
        "    #26465D\n",
        "}\n",
        "\n",
        ".logo {\n",
        "    margin: 20px 0 20px 0;\n",
        "}\n",
        "\n",
        "a.anchor-link {\n",
        "    display: none;\n",
        "}\n",
        "\n",
        "h1.title { \n",
        "    font-size: 250%;\n",
        "}\n",
        "\n",
        "</style>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x106672a10>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## What is Machine Learning?\n",
      "\n",
      "Broadly speaking, Machine Learning is a field, related to Artificial Intelligence (AI), concerned about developping algorithms that 'learn from data', i.e. automatically adjust their performance from exposure to information encoded in data. This learning is achieved via **tunable parameters** that are automatically adjusted according to performance criteria.\n",
      "\n",
      "There are two major classes of ML: \n",
      "\n",
      "**Supervised learning**\n",
      ": Algorithms which learn from a training set of *labeled* examples to generalize to the set of all possible inputs. Examples of supervised learning include regression and support vector machines.\n",
      "\n",
      "There are two classes of supervised learning algorithms: \n",
      "\n",
      "1. **classification**: when the label is encoded into a discrete, categorical variable (a *class*)\n",
      "\n",
      "2. **regression**: when the label is encoded into a continuous variable\n",
      "\n",
      "**Unsupervised learning**\n",
      ": Algorithms which learn from a training set of *unlabeled* examples, using the features of the inputs to categorize inputs together according to some statistical criteria. Examples of unsupervised learning include k-means clustering and kernel density estimation.\n",
      "\n",
      "One can also divide Unsupervised learning algorithms into: \n",
      "\n",
      "1. **Dimensionality reduction**: learning a more compact representation of the data\n",
      "2. **Clustering**: separating the data into clusters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Some vocabulary \n",
      "\n",
      "+ ** Instance **: sample\n",
      "+ ** Feature **: explanatory variable, independent variable\n",
      "+ ** label **: class, category, target variable, dependent variable \n",
      "+ ** Categorical **\n",
      "    - Nominal\n",
      "    - Ordinal\n",
      "+ ** Continuous **"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## `Scikit-learn` "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `scikit-learn` package is an open-source library that provides a robust set of machine learning algorithms for Python. It is built upon the core Python scientific stack (*i.e.* NumPy, SciPy, Cython), and has a simple, consistent API, making it useful for a wide range of statistical learning applications."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Representing Data in `scikit-learn`\n",
      "\n",
      "Most machine learning algorithms implemented in scikit-learn expect data to be stored in a\n",
      "**two-dimensional array or matrix**.  The arrays can be\n",
      "either ``numpy`` arrays, or in some cases ``scipy.sparse`` matrices.\n",
      "The size of the array is expected to be `[n_samples, n_features]`\n",
      "\n",
      "- **n_samples:**   The number of samples: each sample is an item to process (e.g. classify).\n",
      "  A sample can be a document, a picture, a sound, a video, an astronomical object,\n",
      "  a row in database or CSV file,\n",
      "  or whatever you can describe with a fixed set of quantitative traits.\n",
      "- **n_features:**  The number of features or distinct traits that can be used to describe each\n",
      "  item in a quantitative manner.  Features are generally real-valued, but may be boolean or\n",
      "  discrete-valued in some cases.\n",
      "\n",
      "The number of features must be fixed in advance. However it can be very high dimensional\n",
      "(e.g. millions of features) with most of them being zeros for a given sample. This is a case\n",
      "where `scipy.sparse` matrices can be useful, in that they are\n",
      "much more memory-efficient than numpy arrays."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The `scikit-learn` interface\n",
      "\n",
      "A great feature about scikit-learn is the consistant API (Application Programmer Interface) which means that once you have learned how one particular algorithm is implemented in scikit-learn, using another algorithm will look very familiar. \n",
      "\n",
      "All objects within scikit-learn share a uniform common basic API consisting of three complementary interfaces: an **estimator** interface for building and \ufb01tting models, a **predictor** interface for making predictions and a **transformer** interface for converting data.\n",
      "\n",
      "The estimator interface is at the core of the library. It de\ufb01nes instantiation mechanisms of objects and exposes a fit method for learning a model from training data. All supervised and unsupervised learning algorithms (*e.g.*, for classi\ufb01cation, regression or clustering) are o\ufb00ered as objects implementing this interface. Machine learning tasks like feature extraction, feature selection or dimensionality reduction are also provided as estimators.\n",
      "\n",
      "Scikit-learn strives to have a uniform interface across all methods; given a scikit-learn *estimator*\n",
      "object named `model`, the following methods are available:\n",
      "\n",
      "- Available in **all Estimators**\n",
      "  + `model.fit()` : fit training data. For supervised learning applications,\n",
      "    this accepts two arguments: the data `X` and the labels `y` (e.g. `model.fit(X, y)`).\n",
      "    For unsupervised learning applications, this accepts only a single argument,\n",
      "    the data `X` (e.g. `model.fit(X)`).\n",
      "- Available in **supervised estimators**\n",
      "  + `model.predict()` : given a trained model, predict the label of a new set of data.\n",
      "    This method accepts one argument, the new data `X_new` (e.g. `model.predict(X_new)`),\n",
      "    and returns the learned label for each object in the array.\n",
      "  + `model.predict_proba()` : For classification problems, some estimators also provide\n",
      "    this method, which returns the probability that a new observation has each categorical label.\n",
      "    In this case, the label with the highest probability is returned by `model.predict()`.\n",
      "  + `model.score()` : for classification or regression problems, most (all?) estimators implement\n",
      "    a score method.  Scores are between 0 and 1, with a larger score indicating a better fit.\n",
      "- Available in **unsupervised estimators**\n",
      "  + `model.transform()` : given an unsupervised model, transform new data into the new basis.\n",
      "    This also accepts one argument `X_new`, and returns the new representation of the data based\n",
      "    on the unsupervised model.\n",
      "  + `model.fit_transform()` : some estimators implement this method,\n",
      "    which more efficiently performs a fit and a transform on the same input data.\n",
      "    \n",
      "The *predictor* interface extends the notion of an estimator by adding a `predict` method that takes an array `X_test` and produces predictions based on the learned parameters of the estimator. In the case of supervised learning estimators, this method typically returns the predicted labels (for *classification*) or values (*regression) computed by the model. Some unsupervised learning estimators may also implement the predict interface, such as k-means, where the predicted values are the cluster labels.\n",
      "\n",
      "Since it is common to modify or \ufb01lter data before feeding it to a learning algorithm, some estimators in the library implement a *transformer* interface which de\ufb01nes a transform method. It takes as input some new data `X_test` and yields as output a transformed version. Preprocessing, feature selection, feature extraction and dimensionality reduction algorithms are all provided as transformers within the library."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We're going to explore successively: \n",
      "\n",
      "+ unsupervised learning, with cluster analysis (k-means), we'll also talk about [dimensionality reduction](http://en.wikipedia.org/wiki/Dimensionality_reduction) with [Principal Component Analysis](http://en.wikipedia.org/wiki/Principal_component_analysis)\n",
      "\n",
      "+ supervised learning, with one example of regression (linear regression) and classification (Support Vector Machines)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To introduce the mechanics of classification algorithms in scikit-learn, we're gonna use a dataset (`wine.dat`) that is the result of chemical analyses of wines grown in the same region in Italy but derived from three different cultivars (i.e. *grapes*). \n",
      "\n",
      "The analysis determined the quantities of 13 constituents found in each of the three types of wines. The goal is to try and retrieve the correct cultivar based on the wine chemical profile.\n",
      "\n",
      "This dataset is available from the University of California Irvine **Learning Databases**, at  www.ics.uci.edu/~mlearn/MLRepository. Reference is C.L. Blake and C. J. Merz (1998). \n",
      "\n",
      "These data are used in the book \"Computational Statistics\" \n",
      "by G.H. Givens and J.A. Hoeting."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(url='http://scikit-learn.org/stable/_static/ml_map.png', width=900)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://scikit-learn.org/stable/_static/ml_map.png\" width=\"900\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "<IPython.core.display.Image at 0x107ed2250>"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wine = pd.read_table(\"./data/wine.dat\", sep='\\s+')\n",
      "\n",
      "attributes = ['region',\n",
      "            'Alcohol',\n",
      "            'Malic acid',\n",
      "            'Ash',\n",
      "            'Alcalinity of ash',\n",
      "            'Magnesium',\n",
      "            'Total phenols',\n",
      "            'Flavanoids',\n",
      "            'Nonflavanoid phenols',\n",
      "            'Proanthocyanins',\n",
      "            'Color intensity',\n",
      "            'Hue',\n",
      "            'OD280/OD315 of diluted wines',\n",
      "            'Proline']\n",
      "\n",
      "wine.columns = attributes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wine.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>region</th>\n",
        "      <th>Alcohol</th>\n",
        "      <th>Malic acid</th>\n",
        "      <th>Ash</th>\n",
        "      <th>Alcalinity of ash</th>\n",
        "      <th>Magnesium</th>\n",
        "      <th>Total phenols</th>\n",
        "      <th>Flavanoids</th>\n",
        "      <th>Nonflavanoid phenols</th>\n",
        "      <th>Proanthocyanins</th>\n",
        "      <th>Color intensity</th>\n",
        "      <th>Hue</th>\n",
        "      <th>OD280/OD315 of diluted wines</th>\n",
        "      <th>Proline</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1.51</td>\n",
        "      <td>-0.56</td>\n",
        "      <td> 0.23</td>\n",
        "      <td>-1.17</td>\n",
        "      <td> 1.91</td>\n",
        "      <td> 0.81</td>\n",
        "      <td> 1.03</td>\n",
        "      <td>-0.66</td>\n",
        "      <td> 1.22</td>\n",
        "      <td> 0.25</td>\n",
        "      <td> 0.36</td>\n",
        "      <td> 1.84</td>\n",
        "      <td> 1.01</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0.25</td>\n",
        "      <td>-0.50</td>\n",
        "      <td>-0.83</td>\n",
        "      <td>-2.48</td>\n",
        "      <td> 0.02</td>\n",
        "      <td> 0.57</td>\n",
        "      <td> 0.73</td>\n",
        "      <td>-0.82</td>\n",
        "      <td>-0.54</td>\n",
        "      <td>-0.29</td>\n",
        "      <td> 0.40</td>\n",
        "      <td> 1.11</td>\n",
        "      <td> 0.96</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0.20</td>\n",
        "      <td> 0.02</td>\n",
        "      <td> 1.11</td>\n",
        "      <td>-0.27</td>\n",
        "      <td> 0.09</td>\n",
        "      <td> 0.81</td>\n",
        "      <td> 1.21</td>\n",
        "      <td>-0.50</td>\n",
        "      <td> 2.13</td>\n",
        "      <td> 0.27</td>\n",
        "      <td> 0.32</td>\n",
        "      <td> 0.79</td>\n",
        "      <td> 1.39</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1.69</td>\n",
        "      <td>-0.35</td>\n",
        "      <td> 0.49</td>\n",
        "      <td>-0.81</td>\n",
        "      <td> 0.93</td>\n",
        "      <td> 2.48</td>\n",
        "      <td> 1.46</td>\n",
        "      <td>-0.98</td>\n",
        "      <td> 1.03</td>\n",
        "      <td> 1.18</td>\n",
        "      <td>-0.43</td>\n",
        "      <td> 1.18</td>\n",
        "      <td> 2.33</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0.29</td>\n",
        "      <td> 0.23</td>\n",
        "      <td> 1.84</td>\n",
        "      <td> 0.45</td>\n",
        "      <td> 1.28</td>\n",
        "      <td> 0.81</td>\n",
        "      <td> 0.66</td>\n",
        "      <td> 0.23</td>\n",
        "      <td> 0.40</td>\n",
        "      <td>-0.32</td>\n",
        "      <td> 0.36</td>\n",
        "      <td> 0.45</td>\n",
        "      <td>-0.04</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 14 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "   region  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
        "0       1     1.51       -0.56  0.23              -1.17       1.91   \n",
        "1       1     0.25       -0.50 -0.83              -2.48       0.02   \n",
        "2       1     0.20        0.02  1.11              -0.27       0.09   \n",
        "3       1     1.69       -0.35  0.49              -0.81       0.93   \n",
        "4       1     0.29        0.23  1.84               0.45       1.28   \n",
        "\n",
        "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
        "0           0.81        1.03                 -0.66             1.22   \n",
        "1           0.57        0.73                 -0.82            -0.54   \n",
        "2           0.81        1.21                 -0.50             2.13   \n",
        "3           2.48        1.46                 -0.98             1.03   \n",
        "4           0.81        0.66                  0.23             0.40   \n",
        "\n",
        "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
        "0             0.25  0.36                          1.84     1.01  \n",
        "1            -0.29  0.40                          1.11     0.96  \n",
        "2             0.27  0.32                          0.79     1.39  \n",
        "3             1.18 -0.43                          1.18     2.33  \n",
        "4            -0.32  0.36                          0.45    -0.04  \n",
        "\n",
        "[5 rows x 14 columns]"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grape = wine.pop('region')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "**y** is our target "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = grape.values\n",
      "X = wine.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import svm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc = svm.SVC(kernel='rbf')\n",
      "\n",
      "svc.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "score() takes exactly 3 arguments (1 given)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-17-ff923c7cadaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mTypeError\u001b[0m: score() takes exactly 3 arguments (1 given)"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Now we're gonna use decision trees"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import tree\n",
      "from sklearn import cross_validation\n",
      "\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
      "        X, y, test_size=0.4, random_state=0)\n",
      "\n",
      "clf = tree.DecisionTreeClassifier(criterion='entropy',\n",
      "                                  max_features=\"auto\",\n",
      "                                  min_samples_leaf=10)\n",
      "clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "DecisionTreeClassifier(compute_importances=None, criterion='entropy',\n",
        "            max_depth=None, max_features='auto', min_density=None,\n",
        "            min_samples_leaf=10, min_samples_split=2, random_state=None,\n",
        "            splitter='best')"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "preds = clf.predict(X_test)\n",
      "pd.crosstab(y_test, preds, rownames=['actual'], \n",
      "            colnames=['prediction'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th>prediction</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>actual</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 21</td>\n",
        "      <td>  1</td>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  2</td>\n",
        "      <td> 17</td>\n",
        "      <td> 12</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>  4</td>\n",
        "      <td>  0</td>\n",
        "      <td> 15</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "prediction   1   2   3\n",
        "actual                \n",
        "1           21   1   0\n",
        "2            2  17  12\n",
        "3            4   0  15"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Random forest classifier\n",
      "\n",
      "\n",
      "\n",
      "N jobs "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "rf = RandomForestClassifier(n_jobs=4)\n",
      "\n",
      "rf.fit(X_train, y_train)\n",
      "\n",
      "preds = rf.predict(X_test)\n",
      "\n",
      "pd.crosstab(y_test, preds, rownames=['actual'], \n",
      "            colnames=['prediction'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th>prediction</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>actual</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 22</td>\n",
        "      <td>  0</td>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  0</td>\n",
        "      <td> 28</td>\n",
        "      <td>  3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>  0</td>\n",
        "      <td>  0</td>\n",
        "      <td> 19</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "prediction   1   2   3\n",
        "actual                \n",
        "1           22   0   0\n",
        "2            0  28   3\n",
        "3            0   0  19"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.ols?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, fold in enumerate(KFold(len(salmon), n_folds=nfolds, \n",
      "                               shuffle=True)):\n",
      "    training, validation = fold\n",
      "    y, x = salmon.values[training].T\n",
      "    axes[i].plot(x, y, 'ro')\n",
      "    y, x = salmon.values[validation].T\n",
      "    axes[i].plot(x, y, 'bo')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### example of Leave One Out cross-validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "loo = cross_validation.LeaveOneOut(len(X))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for train_index, test_index in loo:\n",
      "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "    X_train, X_test = X[train_index], X[test_index]\n",
      "    y_train, y_test = y[train_index], y[test_index]\n",
      "    print(X_train, X_test, y_train, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "pandas has an ordinary least square function "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.ols("
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}