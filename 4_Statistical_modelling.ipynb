{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Statistical data modelling with Scipy and Statsmodels"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this notebook we're gonna give a few examples of statistical data modelling, using first scipy to fit *data* to a particular **distribution**, then using **statsmodel** to model the relationship between an dependent variable and an  independant variable (linear regression)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import stats "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<hr size=5>\n",
      "\n",
      "## Distributions and fitting data to distributions with scipy.stats"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stats.distributions."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create a (continous) random variable with normal distribution\n",
      "Y = stats.distributions.norm()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.linspace(-5,5,100)\n",
      "\n",
      "fig, axes = plt.subplots(3,1, sharex=True, figsize=(10,10))\n",
      "\n",
      "# plot the probability distribution function (PDF)\n",
      "axes[0].plot(x, Y.pdf(x))\n",
      "axes[0].set_title('PDF')\n",
      "\n",
      "# plot the commulative distributin function (CDF)\n",
      "axes[1].plot(x, Y.cdf(x));\n",
      "axes[1].set_title('CDF')\n",
      "\n",
      "# plot histogram of 1000 random realizations of the variable Y ~ N(0,1)\n",
      "axes[2].hist(Y.rvs(size=1000), bins=20);\n",
      "axes[2].set_title('Random Variable');\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Fitting data to a particular distribution\n",
      "\n",
      "\n",
      "An recurring statistical problem is finding estimates of the relevant parameters that correspond to the distribution that best represents our data. In **parametric** inference, we specify *a priori* a suitable distribution, then choose the parameters that best fit the data.\n",
      "\n",
      "We're going to see:\n",
      "\n",
      "* The **Method of moments** chooses the parameters so that the sample moments (typically the sample mean and variance) match the theoretical moments of our chosen distribution.\n",
      "* The **Maximum likelihood** chooses the parameters to maximize the likelihood, which measures how likely it is to observe our given sample given the parameters. This is effectively done by **optimization**\n",
      "\n",
      "A real life example: Monthly rainfall amounts at Auckland Airport station"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.read_excel('./data/AKL_aero_rain_monthly.xlsx', sheetname='AKL',index_col=['date'], parse_dates=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['rain'].hist(normed=True, bins=20, grid=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are a few possible choices, but one suitable alternative is the [**gamma distribution**](http://en.wikipedia.org/wiki/Gamma_distribution):\n",
      "\n",
      "There are three different parametrizations in common use, we're gonna use the the one below, with shape parameter $\\alpha$ and an inverse scale parameter $\\beta$ called a *rate parameter*.\n",
      "\n",
      "<div style=\"font-size: 120%;\">  \n",
      "$$x \\sim \\text{Gamma}(\\alpha, \\beta) = \\frac{\\beta^{\\alpha}x^{\\alpha-1}e^{-\\beta x}}{\\Gamma(\\alpha)}$$\n",
      "</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1) Fitting by the method of moments"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The ***method of moments*** simply assigns the empirical mean and variance to their theoretical counterparts, so that we can solve for the parameters.\n",
      "\n",
      "So, for the gamma distribution, it turns out (see the relevant section in [the wikipedia article](http://en.wikipedia.org/wiki/Gamma_distribution)) that the mean and variance are:\n",
      "\n",
      "<div style=\"font-size: 120%;\">  \n",
      "$$ \\hat{\\mu} = \\alpha \\beta $$\n",
      "$$ \\hat{\\sigma}^2 = \\alpha \\beta^2 $$\n",
      "</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, if we solve for $\\alpha$ and $\\beta$, using the **sample** mean ($\\bar{X}$) and variance ($S^2$), we can use a gamma distribution to describe our data:\n",
      "\n",
      "<div style=\"font-size: 120%;\">  \n",
      "$$ \\alpha = \\frac{\\bar{X}^2}{S^2}, \\, \\beta = \\frac{S^2}{\\bar{X}} $$\n",
      "</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "first step: we calculate the **sample mean and variance**, using pandas convenience methods "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precip_mean = data['rain'].mean() # sample mean \n",
      "precip_var = data['rain'].var() # sample variance"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "second step: we calculate the parameters $\\alpha$ and $\\beta$ using the relations above"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alpha_mom = precip_mean ** 2 / precip_var\n",
      "beta_mom = precip_var / precip_mean"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats.distributions import gamma "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The implementation of the Gamma function in scipy requires a *location* parameter, left to zero"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gmom = gamma(alpha_mom, 0, beta_mom)\n",
      "\n",
      "#or gmom = gamma(alpha_mom, scale=beta_mom)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(data['rain'], normed=True, bins=20)\n",
      "plt.plot(np.linspace(0, 300, 100), gmom.pdf(np.linspace(0, 300, 100)), lw=3)\n",
      "plt.grid('off')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2) Maximum Likelihood Estimates using the .fit() method"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shape,loc,scale = gamma.fit(data['rain'].values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shape,loc,scale"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alpha_mom, beta_mom"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gmle = gamma(shape,loc,scale)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gmle."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f, (ax0, ax1) = plt.subplots(1,2,figsize=(13,5))\n",
      "\n",
      "ax0.hist(data['rain'], normed=True, bins=20, color='0.6')\n",
      "ax0.plot(np.linspace(0, 300, 100), gmle.pdf(np.linspace(0, 300, 100)), 'b-', lw=2, label='MLE')\n",
      "ax0.plot(np.linspace(0, 300, 100), gmom.pdf(np.linspace(0, 300, 100)), 'r-', lw=2, label='Moments')\n",
      "ax0.legend()\n",
      "ax0.set_title('Histogram and fitted PDFs')\n",
      "ax1.plot(np.linspace(0, 300, 100), gmle.cdf(np.linspace(0, 300, 100)), 'b-', lw=2, label='MLE')\n",
      "ax1.plot(np.linspace(0, 300, 100), gmom.cdf(np.linspace(0, 300, 100)), 'r-', lw=2, label='Moments')\n",
      "ax1.legend()\n",
      "ax1.set_title('CDFs');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Goodness of fit** tests are available in scipy.stats, through e.g. \n",
      "\n",
      "+ the Kolmogorov-Smirnoff test (`scipy.stats.kstest`)\n",
      "+ the Anderson-Darling test (`scipy.stats.anderson`)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import kstest"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kstest?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The null hypothesis is that the two distributions are **identical**, i.e. you **reject** the null hypothesis that the two samples were drawn from the same distribution if the *p*-value is less than your significance level"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kstest(data['rain'].values, 'gamma', (shape, loc, scale))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kstest(data['rain'].values, 'gamma', (alpha_mom, 0, beta_mom))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<hr size=3>\n",
      "\n",
      "#### Maximum Likelihood Estimation from first principles\n",
      "\n",
      "Some stuff to work on your own, coming from the excellent series of Notebooks created by [Christopher Fonnesbeck](http://biostat.mc.vanderbilt.edu/wiki/Main/ChrisFonnesbeck), and available [at his github repo](https://github.com/fonnesbeck/statistical-analysis-python-tutorial): You're going to see **how the Maximum Likelihood Estimates methods works from first principles**, using the optimization routines in [scipy.optimize](http://docs.scipy.org/doc/scipy/reference/optimize.html). "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "remember that the formula for the Gamma distribution PDF is \n",
      "\n",
      "<div style=\"font-size: 120%;\">  \n",
      "$$x \\sim \\text{Gamma}(\\alpha, \\beta) = \\frac{\\beta^{\\alpha}x^{\\alpha-1}e^{-\\beta x}}{\\Gamma(\\alpha)}$$\n",
      "</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Going back to the rainfall data, if we are using a gamma distribution we need to **maximize**:\n",
      "\n",
      "$$\\begin{align}l(\\alpha,\\beta) &= \\sum_{i=1}^n \\log[\\beta^{\\alpha} x^{\\alpha-1} e^{-x\\beta}\\Gamma(\\alpha)^{-1}] \\cr \n",
      "&= n[(\\alpha-1)\\overline{\\log(x)} - \\bar{x}\\beta + \\alpha\\log(\\beta) - \\log\\Gamma(\\alpha)]\\end{align}$$\n",
      "\n",
      "(*Its usually easier to work in the log scale*)\n",
      "\n",
      "where $n = 596$ (some values are missing in the time-series) and the bar indicates an average over all *i*. We choose $\\alpha$ and $\\beta$ to maximize $l(\\alpha,\\beta)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Finding the MLE\n",
      "\n",
      "To find the maximum of any function, we typically take the *derivative* with respect to the variable to be maximized, set it to zero and solve for that variable. \n",
      "\n",
      "$$\\frac{\\partial l(\\alpha,\\beta)}{\\partial \\beta} = n\\left(\\frac{\\alpha}{\\beta} - \\bar{x}\\right) = 0$$\n",
      "\n",
      "Which can be solved as $\\beta = \\alpha/\\bar{x}$. However, plugging this into the derivative with respect to $\\alpha$ yields:\n",
      "\n",
      "$$\\frac{\\partial l(\\alpha,\\beta)}{\\partial \\alpha} = \\log(\\alpha) + \\overline{\\log(x)} - \\log(\\bar{x}) - \\frac{\\Gamma(\\alpha)'}{\\Gamma(\\alpha)} = 0$$\n",
      "\n",
      "This has no closed form solution. We must use ***numerical optimization***!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Numerical optimization uses algorithms take an initial \"guess\" at the solution, and iteratively improve the guess until it gets \"close enough\" to the answer.\n",
      "\n",
      "Here, we will use [Newton-Raphson algorithm](http://en.wikipedia.org/wiki/Newton%27s_method_in_optimization):\n",
      "\n",
      "<div style=\"font-size: 120%;\">  \n",
      "$$x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}$$\n",
      "</div>  \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "which is available from [scipy.optimize](http://docs.scipy.org/doc/scipy/reference/optimize.html), and called `newton`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.optimize import newton"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below is a simple illustration of how the Newton-Raphson alogorithm works, using an arbitrary function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# some function\n",
      "func = lambda x: 3./(1 + 400*np.exp(-2*x)) - 1\n",
      "xvals = np.linspace(0, 6)\n",
      "\n",
      "\n",
      "# plot\n",
      "\n",
      "f, ax = plt.subplots(figsize=(8,8))\n",
      "\n",
      "ax.plot(xvals, func(xvals), lw=2)\n",
      "ax.text(5.3, 2.1, '$f(x)$', fontsize=18)\n",
      "\n",
      "# zero line\n",
      "ax.plot([0,6], [0,0], 'k-', lw=2)\n",
      "\n",
      "# value at step n\n",
      "ax.plot([4,4], [0,func(4)], 'k--', lw=2)\n",
      "ax.text(4, -.2, '$x_n$', fontsize=18)\n",
      "\n",
      "# tangent line\n",
      "tanline = lambda x: -0.858 + 0.626*x\n",
      "ax.plot(xvals, tanline(xvals), 'r--', lw=2)\n",
      "\n",
      "# point at step n+1\n",
      "xprime = 0.858/0.626\n",
      "ax.plot([xprime, xprime], [tanline(xprime), func(xprime)], 'k--', lw=2)\n",
      "ax.text(xprime+.1, -.2, '$x_{n+1}$', fontsize=18); "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<hr size=5>\n",
      "## Non Parametric Density estimation: Kernel Density Estimation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In some instances, we may not be interested in the parameters of a particular distribution of data, but just a smoothed representation of the data. In this case, we can estimate the distribution *non-parametrically* (i.e. making no assumptions about the form of the underlying distribution) using [Kernel Density Estimation](http://en.wikipedia.org/wiki/Kernel_density_estimation).\n",
      "\n",
      "If you are interested into an excellent discussion of the various options in Python to perform Kernel Density Estimation, have a look at this [post](http://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/) on Jake VanderPlas blog [Pythonic Perambulations](http://jakevdp.github.io/). Some more stuff on KDE is available [here](http://www.mglerner.com/blog/?p=28) from Michael Lerner.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In a nutschell, (Gaussian) Kernel density estimation works 'simply' by summing up Gaussian functions (PDFs) centered on each data point. Each Gaussian function is characterized by a location parameter (the value of the data point), and a scale parameter ($\\sigma$) which is related to the 'bandwith' of your (Gaussian) kernel."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Some random data\n",
      "y = np.random.random(15) * 10\n",
      "y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.linspace(0, 10, 100)\n",
      "# Smoothing parameter\n",
      "s = 0.4\n",
      "# Calculate the kernels\n",
      "kernels = np.transpose([stats.distributions.norm.pdf(x, yi, s) for yi in y])\n",
      "plt.plot(x, kernels, 'k:')\n",
      "plt.plot(x, kernels.sum(1))\n",
      "plt.plot(y, np.zeros(len(y)), 'ro', ms=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Kernel Density Estimation is implemented in scipy.stats by [scipy.stats.gaussian_kde](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gaussian_kde.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import gaussian_kde"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f, ax = plt.subplots(figsize=(7,7))\n",
      "density = gaussian_kde(data['rain'])\n",
      "xgrid = np.linspace(data['rain'].min(), data['rain'].max(), 100)\n",
      "\n",
      "ax.hist(data['rain'], bins=20, normed=True, label='data', alpha=.6)\n",
      "ax.plot(xgrid, density(xgrid), 'r-', lw=2, label='KDE')\n",
      "ax.legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<hr size=5>\n",
      "## Generalized Linear Models with statsmodel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Statsmodels](http://statsmodels.sourceforge.net) is a Python module that allows users to explore data, estimate statistical models, and perform statistical tests."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from talktools import website; \n",
      "website('http://statsmodels.sourceforge.net', width=1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the previous parts we considered a single variable, and we wanted to describe its distribution, either using a **parametric** approach (fitting the data to a *known distribution*) or **non-parametric** approach (get a *smooth* representation of its empirical distribution / histogram using *Kernel Density Estimation*)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another general, primary goal of many statistical data analysis tasks is to relate the influence of one variable ($X$) on another ($Y$). For example, we may want to know how different levels of contaminants in the water influence the reproduction of one marine invertebrate species, or how the variation of some remote climate phenomenon influence rainfall variability in a specific region of New Zealand. In this case as well one needs to decide on the particular form of the model that relates $Y$ to $X$ (e.g. what **function** we will consider: *linear*, *quadratic*, *logistic*, etc ...) then use algorithms to *estimate* the **parameters** of this model."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recognizing that additional factors other than $X$ (the ones we have measured or are interested in) may influence the response variable $Y$, we can build a model to characterize the relationship \n",
      "\n",
      "<div style=\"font-size: 120%;\">  \n",
      "$y_i = f(x_i) + \\epsilon_i$\n",
      "</div>  \n",
      "\n",
      "Where $\\epsilon_i$ is the difference between the modelled and observed values."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Linear Model\n",
      "\n",
      "for a **linear** model: \n",
      "    \n",
      "<div style=\"font-size: 120%;\">  \n",
      "$y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$\n",
      "</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We would like to select $\\beta_0, \\beta_1$ so that the difference between the predictions and the observations ($\\epsilon_i$) is zero, but this is not usually possible. Instead, we choose a reasonable criterion: ***the smallest sum of the squared differences between $\\hat{y}$ and $y$***.\n",
      "\n",
      "<div style=\"font-size: 120%;\">  \n",
      "$$R^2 = \\sum_i (y_i - [\\beta_0 + \\beta_1 x_i])^2 = \\sum_i \\epsilon_i^2 $$  \n",
      "</div>\n",
      "\n",
      "Squaring serves two purposes: (1) to prevent positive and negative values from cancelling each other out and (2) to strongly penalize large deviations. Whether the latter is a good thing or not depends on the goals of the analysis.\n",
      "\n",
      "In other words, we will select the parameters that minimize the squared error of the model."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we're going to model the SOI (Southern Oscillation Index) as a function of the Sea Surface Temperature anomalies in the central east Pacific (NINO 3.4 index). We've seen in the previous notebook that these time-series are linearly related (Pearson'R correlation coefficient ~ 0.71) so setting up and estimating the parameters of a linear model seems like a good idea ... "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.read_csv('./data/soi_nino.csv', index_col=0, parse_dates=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.corr()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import statsmodels.api as sm\n",
      "\n",
      "lm1_mod = sm.OLS(data['SOI'], sm.add_constant(data['nino']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lm1_fit = lm1_mod.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lm1_fit.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The statsmodels library has also a **formula** API that allows you to enter your model using a syntax which should be familiar to R users. The variable names are simply the names of the corresponding columns in the pandas DataFrame, which is given as the second argument. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from statsmodels.formula.api import ols as OLS"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lm2_mod = OLS('SOI ~ nino', data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lm2_fit = lm2_mod.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lm2_fit.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f, ax = plt.subplots(figsize=(7,7))\n",
      "\n",
      "ax.plot(data['nino'], data['SOI'], 'k+')\n",
      "\n",
      "ax.plot(data['nino'], lm2_fit.fittedvalues, 'b-')\n",
      "# or \n",
      "#ax.plot(data['nino'], lm2_fit.predict(), 'b-')\n",
      "\n",
      "ax.set_xlabel('NINO 3.4')\n",
      "ax.set_ylabel('SOI')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A quick demo of the [seaborn](https://github.com/mwaskom/seaborn) library, which is built on top of statsmodels\n",
      "\n",
      "To get and install seaborn, issue these command in a terminal: \n",
      "\n",
      "    conda install pip \n",
      "    pip install seaborn\n",
      "    \n",
      "If it doesnt work: \n",
      "\n",
      "1. download it from [https://github.com/mwaskom/seaborn/archive/master.zip](https://github.com/mwaskom/seaborn/archive/master.zip)\n",
      "\n",
      "2. unzip the archive and get into the directory created\n",
      "\n",
      "3. run: \n",
      "\n",
      "    ```python setup.py build```  \n",
      "    ```python setup.py install```\n",
      "    \n",
      "If that fails complaining about missing libraries, you might have to install them with `pip`, e.g. \n",
      "\n",
      "    pip install husl\n",
      "    pip install moss\n",
      "    \n",
      "    \n",
      " "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import seaborn as sns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.regplot(\"nino\", \"SOI\", data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext load_style"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_style talk.css"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "\n",
        ".rendered_html {\n",
        "    font-family: \"proxima-nova\", helvetica;\n",
        "    font-size: 130%;\n",
        "    line-height: 1.5;\n",
        "}\n",
        "\n",
        ".rendered_html h1 {\n",
        "    margin: 0.25em 0em 0.5em;\n",
        "    color: #015C9C;\n",
        "    text-align: center;\n",
        "    line-height: 1.2; \n",
        "    page-break-before: always;\n",
        "}\n",
        "\n",
        ".rendered_html h2 {\n",
        "    margin: 1.1em 0em 0.5em;\n",
        "    color: #26465D;\n",
        "    line-height: 1.2;\n",
        "}\n",
        "\n",
        ".rendered_html h3 {\n",
        "    margin: 1.1em 0em 0.5em;\n",
        "    color: #002845;\n",
        "    line-height: 1.2;\n",
        "}\n",
        "\n",
        ".rendered_html li {\n",
        "    line-height: 1.5; \n",
        "}\n",
        "\n",
        "/*.prompt {\n",
        "    font-size: 120%; \n",
        "}*/\n",
        "\n",
        ".CodeMirror-lines {\n",
        "    font-size: 110%; \n",
        "}\n",
        "\n",
        "/*.output_area {\n",
        "    font-size: 120%; \n",
        "}*/\n",
        "\n",
        "/*#notebook {\n",
        "    background-image: url('files/images/witewall_3.png');\n",
        "}*/\n",
        "\n",
        "h1.bigtitle {\n",
        "    margin: 4cm 1cm 4cm 1cm;\n",
        "    font-size: 300%;\n",
        "}\n",
        "\n",
        "h3.point {\n",
        "    font-size: 200%;\n",
        "    text-align: center;\n",
        "    margin: 2em 0em 2em 0em;\n",
        "    #26465D\n",
        "}\n",
        "\n",
        ".logo {\n",
        "    margin: 20px 0 20px 0;\n",
        "}\n",
        "\n",
        "a.anchor-link {\n",
        "    display: none;\n",
        "}\n",
        "\n",
        "h1.title { \n",
        "    font-size: 250%;\n",
        "}\n",
        "\n",
        "</style>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x10ca6ae10>"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}